{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 50_000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable:\n",
    "    \n",
    "    def __init__(self, chars: str):\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "    \n",
    "    def encode(self, C: str, num_rows: int) -> np.ndarray:\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x: np.ndarray, calc_argmax = True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[c] for c in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    result = []\n",
    "    no_of_digits = np.random.randint(1, DIGITS + 1)\n",
    "    for _ in range(no_of_digits):\n",
    "        random_num = np.random.choice(list('0123456789'))\n",
    "        result.append(random_num)\n",
    "    return int(''.join(result))\n",
    "\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    a, b = f(), f()\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    q = f'{a}+{b}'\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(f'Total questions: {len(questions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS+1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS+1)\n",
    "\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_layers = 1\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "for _ in range(num_layers):\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7403 - accuracy: 0.3621 - val_loss: 1.5210 - val_accuracy: 0.4293\n",
      "Q 58+377  T 435  ☒ 355 \n",
      "Q 440+6   T 446  ☒ 454 \n",
      "Q 880+204 T 1084 ☒ 1010\n",
      "Q 77+36   T 113  ☒ 13  \n",
      "Q 76+341  T 417  ☒ 451 \n",
      "Q 6+559   T 565  ☒ 555 \n",
      "Q 25+444  T 469  ☒ 455 \n",
      "Q 2+669   T 671  ☒ 664 \n",
      "Q 79+85   T 164  ☒ 185 \n",
      "Q 310+7   T 317  ☒ 133 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3081 - accuracy: 0.5134 - val_loss: 1.1278 - val_accuracy: 0.5805\n",
      "Q 674+517 T 1191 ☒ 1102\n",
      "Q 6+559   T 565  ☒ 552 \n",
      "Q 567+72  T 639  ☒ 642 \n",
      "Q 780+20  T 800  ☒ 792 \n",
      "Q 512+81  T 593  ☒ 592 \n",
      "Q 9+141   T 150  ☒ 147 \n",
      "Q 1+978   T 979  ☒ 992 \n",
      "Q 647+57  T 704  ☒ 692 \n",
      "Q 128+287 T 415  ☒ 492 \n",
      "Q 91+543  T 634  ☒ 612 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9956 - accuracy: 0.6340 - val_loss: 0.9074 - val_accuracy: 0.6622\n",
      "Q 15+542  T 557  ☒ 559 \n",
      "Q 453+13  T 466  ☒ 458 \n",
      "Q 422+8   T 430  ☒ 429 \n",
      "Q 162+803 T 965  ☒ 952 \n",
      "Q 980+6   T 986  ☒ 988 \n",
      "Q 1+542   T 543  ☒ 546 \n",
      "Q 974+934 T 1908 ☒ 1816\n",
      "Q 167+96  T 263  ☒ 262 \n",
      "Q 205+3   T 208  ☒ 210 \n",
      "Q 487+353 T 840  ☒ 842 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8286 - accuracy: 0.6967 - val_loss: 0.7780 - val_accuracy: 0.7177\n",
      "Q 145+44  T 189  ☒ 187 \n",
      "Q 26+19   T 45   ☒ 42  \n",
      "Q 73+49   T 122  ☒ 132 \n",
      "Q 476+697 T 1173 ☒ 1177\n",
      "Q 79+2    T 81   ☒ 82  \n",
      "Q 972+98  T 1070 ☒ 1073\n",
      "Q 673+715 T 1388 ☒ 1380\n",
      "Q 34+23   T 57   ☑ 57  \n",
      "Q 398+5   T 403  ☒ 407 \n",
      "Q 212+13  T 225  ☒ 227 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.7216 - accuracy: 0.7373 - val_loss: 0.6940 - val_accuracy: 0.7429\n",
      "Q 565+105 T 670  ☒ 679 \n",
      "Q 784+262 T 1046 ☒ 1030\n",
      "Q 703+169 T 872  ☒ 870 \n",
      "Q 58+570  T 628  ☒ 629 \n",
      "Q 6+327   T 333  ☑ 333 \n",
      "Q 9+156   T 165  ☒ 173 \n",
      "Q 0+440   T 440  ☒ 441 \n",
      "Q 82+73   T 155  ☒ 150 \n",
      "Q 4+41    T 45   ☒ 40  \n",
      "Q 951+522 T 1473 ☒ 1475\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.5319 - accuracy: 0.8094 - val_loss: 0.3759 - val_accuracy: 0.8734\n",
      "Q 27+920  T 947  ☒ 948 \n",
      "Q 510+778 T 1288 ☑ 1288\n",
      "Q 974+934 T 1908 ☒ 1809\n",
      "Q 3+300   T 303  ☒ 304 \n",
      "Q 798+57  T 855  ☒ 847 \n",
      "Q 393+46  T 439  ☒ 438 \n",
      "Q 25+438  T 463  ☑ 463 \n",
      "Q 31+86   T 117  ☒ 118 \n",
      "Q 10+500  T 510  ☒ 522 \n",
      "Q 25+72   T 97   ☒ 90  \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.2856 - accuracy: 0.9164 - val_loss: 0.2072 - val_accuracy: 0.9481\n",
      "Q 91+8    T 99   ☑ 99  \n",
      "Q 501+305 T 806  ☒ 815 \n",
      "Q 709+3   T 712  ☑ 712 \n",
      "Q 371+50  T 421  ☒ 422 \n",
      "Q 1+846   T 847  ☑ 847 \n",
      "Q 16+449  T 465  ☑ 465 \n",
      "Q 864+708 T 1572 ☑ 1572\n",
      "Q 873+6   T 879  ☑ 879 \n",
      "Q 197+634 T 831  ☑ 831 \n",
      "Q 295+0   T 295  ☒ 294 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1635 - accuracy: 0.9611 - val_loss: 0.1209 - val_accuracy: 0.9728\n",
      "Q 179+399 T 578  ☒ 577 \n",
      "Q 8+392   T 400  ☑ 400 \n",
      "Q 227+75  T 302  ☑ 302 \n",
      "Q 267+2   T 269  ☑ 269 \n",
      "Q 780+305 T 1085 ☑ 1085\n",
      "Q 167+86  T 253  ☑ 253 \n",
      "Q 86+900  T 986  ☑ 986 \n",
      "Q 555+383 T 938  ☑ 938 \n",
      "Q 510+778 T 1288 ☑ 1288\n",
      "Q 217+720 T 937  ☑ 937 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.1112 - accuracy: 0.9739 - val_loss: 0.0765 - val_accuracy: 0.9829\n",
      "Q 529+947 T 1476 ☒ 1475\n",
      "Q 31+447  T 478  ☑ 478 \n",
      "Q 444+433 T 877  ☑ 877 \n",
      "Q 65+72   T 137  ☑ 137 \n",
      "Q 176+83  T 259  ☑ 259 \n",
      "Q 905+1   T 906  ☑ 906 \n",
      "Q 752+21  T 773  ☑ 773 \n",
      "Q 82+620  T 702  ☑ 702 \n",
      "Q 238+904 T 1142 ☑ 1142\n",
      "Q 72+269  T 341  ☑ 341 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0789 - accuracy: 0.9813 - val_loss: 0.0524 - val_accuracy: 0.9894\n",
      "Q 193+640 T 833  ☑ 833 \n",
      "Q 62+165  T 227  ☑ 227 \n",
      "Q 463+23  T 486  ☑ 486 \n",
      "Q 608+36  T 644  ☑ 644 \n",
      "Q 6+701   T 707  ☑ 707 \n",
      "Q 935+25  T 960  ☑ 960 \n",
      "Q 744+30  T 774  ☑ 774 \n",
      "Q 5+856   T 861  ☑ 861 \n",
      "Q 8+938   T 946  ☑ 946 \n",
      "Q 766+96  T 862  ☑ 862 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0547 - accuracy: 0.9876 - val_loss: 0.0468 - val_accuracy: 0.9898\n",
      "Q 169+44  T 213  ☑ 213 \n",
      "Q 303+35  T 338  ☑ 338 \n",
      "Q 972+826 T 1798 ☑ 1798\n",
      "Q 733+60  T 793  ☑ 793 \n",
      "Q 349+47  T 396  ☑ 396 \n",
      "Q 471+80  T 551  ☑ 551 \n",
      "Q 514+822 T 1336 ☒ 1335\n",
      "Q 374+361 T 735  ☑ 735 \n",
      "Q 751+65  T 816  ☑ 816 \n",
      "Q 398+846 T 1244 ☑ 1244\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0516 - accuracy: 0.9862 - val_loss: 0.0343 - val_accuracy: 0.9929\n",
      "Q 869+51  T 920  ☑ 920 \n",
      "Q 496+90  T 586  ☑ 586 \n",
      "Q 984+60  T 1044 ☑ 1044\n",
      "Q 846+93  T 939  ☑ 939 \n",
      "Q 278+831 T 1109 ☑ 1109\n",
      "Q 342+45  T 387  ☑ 387 \n",
      "Q 213+991 T 1204 ☑ 1204\n",
      "Q 294+365 T 659  ☑ 659 \n",
      "Q 849+10  T 859  ☑ 859 \n",
      "Q 857+52  T 909  ☑ 909 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0330 - accuracy: 0.9926 - val_loss: 0.0480 - val_accuracy: 0.9855\n",
      "Q 215+47  T 262  ☑ 262 \n",
      "Q 639+718 T 1357 ☑ 1357\n",
      "Q 981+12  T 993  ☑ 993 \n",
      "Q 65+314  T 379  ☑ 379 \n",
      "Q 87+59   T 146  ☑ 146 \n",
      "Q 319+632 T 951  ☑ 951 \n",
      "Q 40+753  T 793  ☑ 793 \n",
      "Q 3+251   T 254  ☑ 254 \n",
      "Q 707+51  T 758  ☑ 758 \n",
      "Q 330+845 T 1175 ☑ 1175\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0495 - accuracy: 0.9872 - val_loss: 0.0365 - val_accuracy: 0.9900\n",
      "Q 471+67  T 538  ☑ 538 \n",
      "Q 561+235 T 796  ☑ 796 \n",
      "Q 593+343 T 936  ☑ 936 \n",
      "Q 146+660 T 806  ☑ 806 \n",
      "Q 56+505  T 561  ☑ 561 \n",
      "Q 63+935  T 998  ☑ 998 \n",
      "Q 162+937 T 1099 ☑ 1099\n",
      "Q 738+495 T 1233 ☑ 1233\n",
      "Q 72+553  T 625  ☑ 625 \n",
      "Q 685+92  T 777  ☑ 777 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.0206 - val_accuracy: 0.9955\n",
      "Q 70+853  T 923  ☑ 923 \n",
      "Q 6+717   T 723  ☑ 723 \n",
      "Q 621+87  T 708  ☑ 708 \n",
      "Q 224+13  T 237  ☑ 237 \n",
      "Q 79+90   T 169  ☑ 169 \n",
      "Q 453+18  T 471  ☑ 471 \n",
      "Q 613+42  T 655  ☑ 655 \n",
      "Q 677+99  T 776  ☑ 776 \n",
      "Q 4+708   T 712  ☑ 712 \n",
      "Q 998+392 T 1390 ☒ 1380\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 0.0479 - val_accuracy: 0.9861\n",
      "Q 803+54  T 857  ☑ 857 \n",
      "Q 310+742 T 1052 ☑ 1052\n",
      "Q 493+6   T 499  ☑ 499 \n",
      "Q 202+7   T 209  ☑ 209 \n",
      "Q 6+702   T 708  ☑ 708 \n",
      "Q 979+277 T 1256 ☑ 1256\n",
      "Q 779+205 T 984  ☑ 984 \n",
      "Q 46+29   T 75   ☑ 75  \n",
      "Q 417+610 T 1027 ☑ 1027\n",
      "Q 15+819  T 834  ☑ 834 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0337 - accuracy: 0.9907 - val_loss: 0.0641 - val_accuracy: 0.9821\n",
      "Q 32+61   T 93   ☑ 93  \n",
      "Q 21+256  T 277  ☑ 277 \n",
      "Q 398+44  T 442  ☑ 442 \n",
      "Q 392+973 T 1365 ☑ 1365\n",
      "Q 3+856   T 859  ☑ 859 \n",
      "Q 40+301  T 341  ☑ 341 \n",
      "Q 44+59   T 103  ☑ 103 \n",
      "Q 167+63  T 230  ☑ 230 \n",
      "Q 631+662 T 1293 ☑ 1293\n",
      "Q 473+28  T 501  ☑ 501 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0096 - accuracy: 0.9986 - val_loss: 0.0099 - val_accuracy: 0.9978\n",
      "Q 97+41   T 138  ☑ 138 \n",
      "Q 57+378  T 435  ☑ 435 \n",
      "Q 240+54  T 294  ☑ 294 \n",
      "Q 607+74  T 681  ☑ 681 \n",
      "Q 21+500  T 521  ☑ 521 \n",
      "Q 429+2   T 431  ☑ 431 \n",
      "Q 67+413  T 480  ☑ 480 \n",
      "Q 41+979  T 1020 ☑ 1020\n",
      "Q 604+58  T 662  ☑ 662 \n",
      "Q 94+63   T 157  ☑ 157 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.2332 - val_accuracy: 0.9285\n",
      "Q 0+849   T 849  ☑ 849 \n",
      "Q 55+931  T 986  ☑ 986 \n",
      "Q 262+486 T 748  ☑ 748 \n",
      "Q 19+594  T 613  ☑ 613 \n",
      "Q 29+270  T 299  ☑ 299 \n",
      "Q 991+651 T 1642 ☒ 1652\n",
      "Q 793+446 T 1239 ☒ 1339\n",
      "Q 0+862   T 862  ☒ 863 \n",
      "Q 96+788  T 884  ☑ 884 \n",
      "Q 611+188 T 799  ☑ 799 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0305 - accuracy: 0.9919 - val_loss: 0.0155 - val_accuracy: 0.9962\n",
      "Q 543+9   T 552  ☑ 552 \n",
      "Q 8+790   T 798  ☑ 798 \n",
      "Q 907+398 T 1305 ☑ 1305\n",
      "Q 91+969  T 1060 ☑ 1060\n",
      "Q 336+59  T 395  ☑ 395 \n",
      "Q 968+312 T 1280 ☑ 1280\n",
      "Q 350+54  T 404  ☑ 404 \n",
      "Q 518+65  T 583  ☑ 583 \n",
      "Q 936+60  T 996  ☑ 996 \n",
      "Q 354+7   T 361  ☑ 361 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0195 - val_accuracy: 0.9949\n",
      "Q 734+73  T 807  ☑ 807 \n",
      "Q 221+482 T 703  ☑ 703 \n",
      "Q 884+3   T 887  ☑ 887 \n",
      "Q 1+270   T 271  ☑ 271 \n",
      "Q 20+630  T 650  ☑ 650 \n",
      "Q 0+910   T 910  ☒ 911 \n",
      "Q 422+8   T 430  ☑ 430 \n",
      "Q 81+636  T 717  ☑ 717 \n",
      "Q 17+380  T 397  ☑ 397 \n",
      "Q 262+812 T 1074 ☒ 1084\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
      "Q 3+150   T 153  ☑ 153 \n",
      "Q 565+9   T 574  ☑ 574 \n",
      "Q 84+291  T 375  ☑ 375 \n",
      "Q 581+82  T 663  ☑ 663 \n",
      "Q 711+13  T 724  ☑ 724 \n",
      "Q 56+759  T 815  ☑ 815 \n",
      "Q 256+31  T 287  ☑ 287 \n",
      "Q 42+51   T 93   ☑ 93  \n",
      "Q 0+84    T 84   ☑ 84  \n",
      "Q 372+79  T 451  ☑ 451 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0070 - val_accuracy: 0.9987\n",
      "Q 747+23  T 770  ☑ 770 \n",
      "Q 78+418  T 496  ☑ 496 \n",
      "Q 49+940  T 989  ☑ 989 \n",
      "Q 2+454   T 456  ☑ 456 \n",
      "Q 422+8   T 430  ☑ 430 \n",
      "Q 822+96  T 918  ☑ 918 \n",
      "Q 557+69  T 626  ☑ 626 \n",
      "Q 724+34  T 758  ☑ 758 \n",
      "Q 925+197 T 1122 ☑ 1122\n",
      "Q 91+453  T 544  ☑ 544 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Q 48+56   T 104  ☑ 104 \n",
      "Q 3+449   T 452  ☑ 452 \n",
      "Q 386+862 T 1248 ☑ 1248\n",
      "Q 259+463 T 722  ☑ 722 \n",
      "Q 8+664   T 672  ☑ 672 \n",
      "Q 152+387 T 539  ☑ 539 \n",
      "Q 29+388  T 417  ☑ 417 \n",
      "Q 25+575  T 600  ☑ 600 \n",
      "Q 53+659  T 712  ☑ 712 \n",
      "Q 7+832   T 839  ☑ 839 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0126 - val_accuracy: 0.9967\n",
      "Q 935+60  T 995  ☑ 995 \n",
      "Q 658+3   T 661  ☑ 661 \n",
      "Q 67+167  T 234  ☑ 234 \n",
      "Q 178+69  T 247  ☑ 247 \n",
      "Q 88+459  T 547  ☑ 547 \n",
      "Q 42+918  T 960  ☑ 960 \n",
      "Q 49+5    T 54   ☑ 54  \n",
      "Q 54+90   T 144  ☑ 144 \n",
      "Q 541+90  T 631  ☑ 631 \n",
      "Q 4+765   T 769  ☑ 769 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.0477 - val_accuracy: 0.9851\n",
      "Q 566+3   T 569  ☑ 569 \n",
      "Q 87+65   T 152  ☑ 152 \n",
      "Q 641+3   T 644  ☑ 644 \n",
      "Q 11+86   T 97   ☑ 97  \n",
      "Q 440+634 T 1074 ☑ 1074\n",
      "Q 173+237 T 410  ☑ 410 \n",
      "Q 65+22   T 87   ☑ 87  \n",
      "Q 223+28  T 251  ☑ 251 \n",
      "Q 76+22   T 98   ☑ 98  \n",
      "Q 85+163  T 248  ☑ 248 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Q 315+23  T 338  ☑ 338 \n",
      "Q 107+16  T 123  ☑ 123 \n",
      "Q 182+7   T 189  ☑ 189 \n",
      "Q 42+737  T 779  ☑ 779 \n",
      "Q 4+699   T 703  ☑ 703 \n",
      "Q 976+39  T 1015 ☑ 1015\n",
      "Q 74+178  T 252  ☑ 252 \n",
      "Q 363+26  T 389  ☑ 389 \n",
      "Q 195+118 T 313  ☑ 313 \n",
      "Q 2+250   T 252  ☑ 252 \n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Q 99+783  T 882  ☑ 882 \n",
      "Q 482+3   T 485  ☑ 485 \n",
      "Q 704+552 T 1256 ☑ 1256\n",
      "Q 147+187 T 334  ☑ 334 \n",
      "Q 632+85  T 717  ☑ 717 \n",
      "Q 967+906 T 1873 ☑ 1873\n",
      "Q 15+741  T 756  ☑ 756 \n",
      "Q 72+701  T 773  ☑ 773 \n",
      "Q 395+214 T 609  ☑ 609 \n",
      "Q 851+303 T 1154 ☑ 1154\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Q 393+76  T 469  ☑ 469 \n",
      "Q 27+72   T 99   ☑ 99  \n",
      "Q 417+202 T 619  ☑ 619 \n",
      "Q 82+203  T 285  ☑ 285 \n",
      "Q 8+830   T 838  ☑ 838 \n",
      "Q 237+282 T 519  ☑ 519 \n",
      "Q 590+648 T 1238 ☑ 1238\n",
      "Q 455+4   T 459  ☑ 459 \n",
      "Q 45+65   T 110  ☑ 110 \n",
      "Q 296+250 T 546  ☑ 546 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    model.fit(x_train, y_train ,batch_size=batch_size, epochs=1, validation_data=(x_val, y_val))\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tensorflow",
   "language": "python",
   "name": "conda-env-py37_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
